train:
  training_args:
    output_dir: models/germeval24/gbert-large/m1
    save_strategy: epoch
    eval_strategy: epoch
    learning_rate: 4e-5
    per_device_train_batch_size: 250
    per_device_eval_batch_size: 250
    num_train_epochs: 8
    save_total_limit: 1
    logging_dir: logs/germeval24/gbert-large/m1
    # metric_for_best_model: eval_f1
    # load_best_model_at_end: true
    # greater_is_better: true
    report_to: none
    fp16: true
  model_name: deepset/gbert-large
  input_col: text
  label_col: bin_one
  model_labels:
  - one_false
  - one_true